---
title: "p8105_hw5_ls3751"
author: "Liucheng Shi"
output: github_document

---

```{r setup, include = FALSE}
library(tidyverse)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_color_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1

Read in the data.

```{r}
homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```



```{r, error = TRUE}
city_prop_test = function(df) {
  
  n_unsovled ...
  n_total ... 
  
  prop.test(.....)
  
}


homicide_df = 
  read_csv("homicide_data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```





## Problem 2

### 2.1 Start with a dataframe containing all file names, iterate over file names and read in data for each subject using purrr::map and saving the result as a new variable in the dataframe

<details>
  <summary>code for data manipulation</summary>
```{r, message = F}
study_df = 
  tibble(
    path = list.files("data"),
  ) %>% 
  mutate(
    path = str_c("data/", path),
    data = map(.x = path, ~read_csv(.x)))
```
</details>

### 2.2 Tidy the result; manipulate file names to include control arm and subject ID

<details>
  <summary>code for data manipulation</summary>
```{r}
study_tidy = study_df %>% 
  unnest(data) %>% 
  mutate(path = str_extract(path,"[a-z][a-z][a-z][\\_][0-9][0-9]")) %>% 
  separate(path, c("arm","id"), sep = "_") %>% 
  mutate(arm = case_when(
    arm == "con" ~ "control",
    arm == "exp" ~ "experimental"),
    id = factor(id), arm = factor(arm)) %>% 
  pivot_longer(week_1:week_8,
               names_to = "week",
               names_prefix = "week_",
               values_to = "observation") %>% 
  mutate(week = factor(week),
         arm = fct_relevel(arm, "experimental"))
```
</details>

### 2.3 Make a spaghetti plot showing observations on each subject over time

```{r Spaghetti plot - observations by arm over time}
study_tidy %>% 
  ggplot(aes(x = week, y = observation, group = id, color = id)) +
  geom_point(size = 1.2) +
  geom_line() +
  labs(
    title = "Spaghetti plot - observations by arm over time",
    x = "Time (week)",
    y = "Observations on each subject") +
  facet_grid(. ~ arm)
```

```{r Spaghetti plot - observations over time}
study_tidy %>% 
  group_by(arm, id) %>% 
  ggplot(aes(x = week, y = observation, color = arm, group = interaction(arm, id))) +
  geom_point(size = 1.2) +
  geom_line() +
  labs(
    title = "Spaghetti plot - observations over time",
    x = "Time (week)",
    y = "Observations on each subject")
```

__Comment__: Observations of experimental and control group at week 1 are approximately the same. Generally, it is noticeable that the observation level in experimental group showed an increasing trend whereas the observation level in control group fluctuated about 1.25 over the period of eight weeks, showing no pattern of change.

## Problem 3 simulation to explore power in a one-sample t-test!!


### 3.1 Generate the datasets for mu = 0,1,2,3,4,5,6

<details>
  <summary>Click here to show code</summary>
```{r, cache = T}
stimulation = function(mu, sd = 5, size = 30, iterate = 5000){
  stimulation = tibble(
    mu = mu,
    trial = seq(1:iterate),
    results = rerun(iterate, rnorm(size, mu, sd)))
  stimulation_df = stimulation %>%
    mutate(ttest = map(.x = results, ~t.test(.x))) %>% 
    mutate(pvalue = map(.x = ttest, ~broom::tidy(.x))) %>% 
    unnest(pvalue) %>% 
    select(mu, trial, estimate, p.value) %>%
    mutate(sample_mean = estimate, p_value = p.value, .keep = "unused",
           decision = case_when(
             p_value < 0.05 ~ "Reject",
             p_value >= 0.05 ~ "Fail to reject"
           ))
  return(stimulation_df)
}

stimulation_combine = tibble(
  output = map(.x = 0:6, ~stimulation(.x)))

stimulation_df = stimulation_combine %>% 
  unnest(cols = c(output))
```
</details>


### 3.2 Make a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis

```{r The association between size effect and power, message = F}
stimulation_df %>% 
  group_by(mu) %>% 
  summarize(percent = length(decision[decision == "Reject"])/n()) %>% 
  as_tibble() %>% 
  ggplot(aes(x = mu, y = percent)) +
  geom_point(size = 1.5) +
  geom_line() +
  labs(
    title = "The association between effect size and power",
    x = "True value of μ",
    y = "Power") 
```


__Comment__: It seems that power is positively associated with effect size that the power would increase as the true value of mu increased from 0 to 6 which means the effect size = (true mean - mu null) would increase. Since variance maintained the same and parameter mu null set to 0, it became more unlikely to see extreme cases of average estimate equals to 0 as the power increased. In other words, the rejection region would be larger as the distribution move leftwards.

### 3.3 Make a plot showing the average estimate of μ^ on the y axis and the true value of μ on the x axis; Make a second plot (or overlay on the first) the average estimate of μ^ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis

<details>
  <summary>code for data manipulation</summary>
```{r, message = F}
all_df = stimulation_df %>% 
  group_by(mu) %>% 
  summarise(avgest_all = mean(sample_mean)) %>% 
  as_tibble()
rejected_df = stimulation_df %>% 
  filter(decision == "Reject") %>% 
  group_by(mu) %>% 
  summarise(avgest_rejected = mean(sample_mean)) %>% 
  as_tibble()
combine_df = left_join(all_df, rejected_df, by = "mu") %>% 
  pivot_longer(avgest_all:avgest_rejected,
               names_to = "type",
               names_prefix = "avgest_",
               values_to = "average_estimate")
```
</details>

```{r The association between average estimate of μ^ and the true value of μ}
combine_df %>% 
  filter(type == "all") %>% 
  ggplot(aes(x = mu, y = average_estimate)) +
  geom_point() +
  geom_line() +
  labs(
    title = "The association between average estimate of μ^ and the true value of μ",
    x = "True value of μ",
    y = "Average estimate")
```

```{r The association between true value of μ and the average estimated μ^ in All and rejected samples}
combine_df %>% 
  ggplot(aes(x = mu, y = average_estimate, color = type)) +
  geom_point() +
  geom_line() +
  labs(
    title = "The association between true value of μ and the average estimated μ^ in All and rejected samples",
    x = "True value of μ",
    y = "Average estimate")
```

__Comment__: The sample average μ^ for all data is approximately equals to the true value of μ which consistent with the underlying population distribution. The sample average of μ^ across tests for which the null is rejected is not approximately equal to the true value of μ especially when the power of the test is not great enough. However, when true value of μ is 0, the average of μ^ is approximately the same as the true value of μ because about same amounts of extreme cases are being rejected. It is noticeable that the difference between the sample average of μ^ of rejected groups and the true values became smaller as the effect size increases. When true value of μ equals to 1 or 2, only samples with greater sample means are rejected so that the average estimate of μ^ is larger than the true value of μ. As more and more samples being rejected, the average estimate of μ^ is approximately equal to the true value.  
